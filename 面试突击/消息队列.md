# 消息队列

1. ## .为什么使用消息队列
   1. #### 解耦:  使原本服务之间调用变为Pub/Sub模式。

      1. 生产者不用考虑消费者发送给谁

         生产者不用考虑是否调用成功、超时

      2. 异步： 使一个服务在同时异步调用多个服务。

      3. 削峰： 高峰期根据服务器负载进行请求消费。

   2. #### 引入后可能出现的问题？

      1. 系统可用性降低：增加系统复杂性，例如MQ故障。
      2. 系统的复杂性提高: 如可能出现消息丢失\消息堆积\消息乱序等。
      3. 一致性问题：消息不一定都同时执行成功，导致数据不一致性问题。

2. ### Kafka、ActiveMQ、RabbitMQ、RocketMQ区别？

   |                     |    ActiveMQ    |               RabbitMQ               |            RocketMQ             |         Kafka         |
   | :-----------------: | :------------: | :----------------------------------: | :-----------------------------: | :-------------------: |
   |       吞吐量        |      万级      |                 万级                 |             十万级              |        十万级         |
   | topic对吞吐量的影响 |                |                                      | 吞吐量可达几百,几千会影响吞吐量 | 几十,几百会影响吞吐量 |
   |       时效性        |  毫秒(ms)级别  |               微秒级别               |          毫秒(ms)级别           |     毫秒(ms)以内      |
   |       可用性        |  高-主从架构   |          高-主从-高可用架构          |          非常高-分布式          |     非常高-分布式     |
   |       可靠性        | 有概率丢失消息 |                                      |           优化可0丢失           |      优化可0丢失      |
   |      功能支持       |    及其完备    | 并发强、性能好、延时低（基于Erlang） |         较完善、扩展好          |        较简单         |

   1. #### ActiveMQ
      
      1. 成熟、功能强大、被大量应用。
      2. 偶尔有消息丢失。
      3. 社区以及国内应用越来越少，维护慢。
      4. 主要基于解耦，较少用于大吞吐量和并发的场景。
   2. #### RibbitMQ
      
      1. ##### 优点：
         
         1. Erlang语言开发，性能好，延时低，万级吞吐量。
         2. 提供良好的管理界面、开源
         3. 社区活跃、用户较多。
      2. ##### 缺点：
         
         1. 吞吐量较低，实现机制较重。
         2. 国内公司无几个做定制，太过于依赖开源社区。
         3. 集群动态扩展很麻烦，源码难阅读。
   3. #### RocketMQ
      
      1. ##### 优点
         
         1. 接口简单易用，具有品牌保障
         2. 日处理消息百亿，有大规模吞吐量
         3. 分布式扩展方便，可靠性、稳定性高
         4. Java编写，阅读方便，支持topic
      2. ##### 缺点
         
         1. 不走JMS协议，仅参考
         2. 可能像dubbo一样停止更新弃用
   4. #### kafka
      
      1. ##### 优点
         
         1. 仅提供较少核心功能，提供超高吞吐量和毫秒级别的延迟
         2. 极高的可用性
         3. 支持较少的topic，保证其吞吐量
         4. 天然适合大数据领域
      2. ##### 缺点
         
         1. 可能消息重复消费
   5. #### 建议：
      
      1. 中小型公司 ->	RabbitMQ 可靠性依赖社区进行维护
      2. 大型公司 -> 可投入源码研究RocketMQ
      3. 大数据实时计算 \ 日志收集 -> kafka

   

   1. #### 如何保证消息队列的高可用性

      1. ##### RabbitMQ

         1. ###### 单机模式

         2. ###### 普通集群

            1. 每个节点都可以寻找到真实数据

            2. 可能在内部产生大量数据传输

               ![](.\imgs\rabbitmq.jpg)

            3. 可用性基本没有任何保障

         3. ##### 镜像集群模式

            1. 原理: 创建一个queue原数据和真实数据都存在的节点,冗余存储
            2. 优点:
               1. 消费任何节点都不会产生问题
               2. 任何一个节点宕机都没有问题
            3. 缺点:
               1. 不是分布式,数据量很大时无法处理

      2. #### kafka的高可用架构

         1. ##### 原理:
            
            1. 每台机器启动一个broker进行,相当于一个节点
            2. 每个机器有多个topic , 每个topic可指定创建一定数量的partition
            3. 生产者将消息存在topic下的partition下
         2. ##### 高可用解决方案;
            
            1. 每个partition都有一个副本,副本和本数据一致的,两个partition中其中有一个是leader，一个是follower，高可用采用选举机制
            2. 只有leader对外提供读写，leader写完后将数据同步到follower
            3. 如果某台机器宕机，kafka会感知leader宕机了，选举下一个leader

   2. ### 如何保证消息不被重复消费？（保证消息的幂等性）

      1. #### kafka

         ![](.\imgs\kafka幂等性offset.png)

         1. 每条消息都有一个offset （消息的顺序序号）
         2. 消费者是按照offset的顺序进行消费
         3. 消费者每消费一条数据都会去提交offset，基于zookeeper去实现，记录了消费者消费的offset。如此时宕机（未提交offset时）kafka会去zookeeper中寻找最后的数据，故会产生重复消息）
         4. 解决方案
            1. offset设置为表的唯一约束，来确保唯一性
            2. Redis中存放offset，来确保唯一性
            3. 内存中缓存offset来确保唯一性

   3. ### 如何保证消息的可靠性

      1. #### RabbitMQ：

         1. ##### 生产者往MQ中写的时候
            
            1. ###### 网络出错导致发送至MQ丢包
               
               1. 在发消息的时候进行try-catch,失败即回滚,否则提交 channel.teSelect  回滚 channel.txRollback(此时消息是同步的,会影响吞吐量);
               2. confirm机制,发送完消,在mq收到消息后会回调生产者的接口,失败也会回调告知生产者
            2. ###### 在未保存至磁盘就宕机:
               
               1. 创建queue时,将其设置为持久化的(AOF RDB)
               2. 发送消息的时候将消息的debrymode设置为2
            3. ###### 消费者拿到消息还未处理就宕机了
               
               1. 只有一种可能,开启了mq的AutoAck模式
            
         2. ##### kafka解决消息丢失

            1. ###### 消费者会自动提交offset,让kafka以为消费者成功消费了消息，从而导致数据丢失-》解决方案为手动提交offset

               ![](.\imgs\kafka同步.png)

            2. ###### 在同步的过程中broker宕机了，使得broker2变成了leader，从而导致数据的丢失，解决方案：

               1. 一个leader至少应有两个副本
               2. 设置min.insync.replicas大于1,设置leader各个follower最少与其同步的数量,即至少一个和你保持同步
               3. producer设置参数: acks = all , 即表示设置生产者写一条数据有多少个leader与其保持同步,all代表全部,如果未达到参数所选,则重试(retries = max) max次,只有成功了才返回写入成功

            3. ###### 生产者丢弃异步数据:

               1. 设置了ack规则,一定不会丢失

         3. ##### 如何保证消息的顺序执行

            1. ###### 场景: 

               如binlog日志同步保证顺序执行

            2. ###### 出错场景:

               1. RibbitMQ: 一个producer多个consumer
               2. kafka: 一个topic,一个consumer,内部多线程消费(或多个partition)

            3. ##### 解决方案:

               1. ###### RabbitMQ解决方案:

                  1. 如有三个消费者则创建三个queue,每个消费者只消费一个queue
                  2. 将必须保证吮吸的数据用同一个queue保存

               2. ###### kafka解决方案:

                  ![](.\imgs\kafka重复消费.jpg)

                  1. 生产者向MQ写的时候一定是能保证顺序写入的(写同一个topic),写的时候指定一个key(如订单的ID),则这个订单相关的数据都会写到一个partition中
                  2. 一个partition只能被一个消费者去消费(kafka机制),故其消费消息也是有序的
                  3. 消费者在消费时默认并发消费,故不能保证顺序
                     1. 建立多个内存队列
                     2. 根据key求hash值,求余放到不同的内存队列中,消费者去消费
                     3. 或者消费者单线程处理(吞吐量会很低)

            4. ###### 消息堆积

               1. ###### 问题: 

                  如遇到消费者不消费,即会出现

               2. ###### 如何快速消费堆积的千万级数据:

                  1. 新建一个topic,此topic内partition为原来的数倍
                  2. 新部署几十台机器,启动几十台临时消费者

               3. ###### 解决方案:

                  1. 设置过期时间,再事后手动写程序,补回数据(不建议)
                  2. 如果磁盘空间满了的话 -> 可同方案1,新增消费者,或者讲消费者消费到空的MQ中,或者直接丢失消息

         




