# 主从架构

1. ### 什么是主从复制架构？

   <img src="..\imgs\主从复制架构.png" style="zoom:67%;" />

   1. 让主节点可复制数据到从节点，保证主从数据的基本一致性
   2. 主节点宕机还可以从从节点执行SQL，保证高可用性
   3. 如长查询SQL，可专用一个库进行查询

2. ### 读写分离架构

   1. 主节点写入数据，但从从节点进行数据查询
   2. 一台专用来写入数据，其他的从节点进行数据查询

3. ### 主从复制工作原理

   1. MySQL在执行增删改的时候会记录binlog日志
   2. 从库有一个IO线程，会负责跟主库建立一个TCP连接，请求主库传输binlog日志给自己
   3. 主库上有一个dump线程，负责通过这个TCP连接把binlog日志输入给从库IO线程
   4. 从库会将binlog日志写入到自己本地的relay日志文件中去
   5. 从库另外有一线程，会读取relay日志里的内容。进行日志重做，即把在主库上的增删改日志都重做一遍

4. 主从架构的搭建

   1. 首先需确保几个MySQL的server-id是不一致的

   2. 主库需要打开binlog日志

   3. 创建主从复制的账号

   4. 如果此时主库跑了一段时间，则须先暂停主库，dump一份主库的分贝

      /usr/local/mysql/bin/mysqldump --single -transaction -uroot -proot --master-data=2 -A bockup.sql

      master-data = 2 意思是说备份SQL里，要记录下此时主库的binlog日志和position号，主从复制准备

   5. 将backup.sql拷贝到从库，并执行

   6. 指定从库复制

      CHANG MASTER TO MASTER = '192.168.31.11' 

      MASTER_USER='blockup' , MASTER_PASSWORD='blockup' , MASTER_LOG_FILE='mysql-bin.000015' , 

      MASTER_LOCI_POSO=1689

      - MASTER_LOG_FILE 和 MASTER_LOG_POS这两个参数在导出的bockup.sql文件头中有

   7. 执行开始复制的命令

      start slave

5. 半同步

   - 上述存在的问题： 主库写完后提交，不管从库是否执行成功，万一此时binlog日志还未同步，主库即宕机，会导致数据丢失
   - 半同步机制：
     - 起码让主库将binlog日志同步给从库才提交事务
   - 两种方式实现
     - AFTER_COMMIT: 主库写入binlog日志后，等待其复制到从库了，就提交自己的事务。等待从库返回成功之后，然后再响应给客户端
     - 默认 ： 主库写入binlog日志后，复制给从库，然后开始等待从库响应。响应成功后主库提交事务，然后返回响应给客户端

6. 半同步配置：

   1. 主库先装插件： 

      install plugin rpl_semi_sync_master soname 'semisync_master_so' 

      set global rpl_semi_sync_master_enable = on

      show plugins

   2. 从库装插件

      install plugin rpl_semi_synv_slave soname 'semisync_slave.so'

      set global rpl_semi_sync_slave_enable = on

   3. 重启从库的IO线程

      stop slave io-thread ; start is-thread

   4. 主库上检查半同步是否同步

      show global status like '%semi%'

7. 基于GTID搭建半复制模式

   1. 主库

      gtid_mode = on

      enforce_gtid_consistency=on

      log_bin = on

      server_id = 自己的server_id

   2. 从库

      gtid_mode = on

      enforce_gtid_consistency = on

      log_slave_update = 1

      server_id = 自己的server_id

## 主从存在的问题

1. ### 为什么会产生延迟?

   1. 主库是多线程并发访问，写入是很快的
   2. 从库同步数据是单个线程慢慢进行拉取
   3. 可用工具来进行主从同步的延时。如percona、toolkit工具集里的heartbeat会在主库中建一张表，
      - 有一个线程定时更新表里的时间戳字段。
      - 从库上有一个monitor线程会负责检查从库同步过来的heartbeat表的时间戳，把时间戳比较下但前时间，即可知道落后了多长的时间
   
2. 会产生什么不良反应？

   1. 刚从主库中写入的数据可能在从库中无法进行读取

3. 怎么解决同步延时问题？

   1. 缩短主从复制的时间，从库也用多线程进行数据同步。5.7以上版本支持多线程进行数据同步，设置如下
      - slave_parallel_workers>0
      - slave_parallel_type = LOGICAL_CLOCK
   2. 如果需要数据一进行写入就得读取到，可以从主库进行数据读取。使用mycat、sharding-jdbc或sharding-sphare之类的中间件即可强制走主库

   

## 高可用架构

1. ### 怎么解决高可用问题？

   高可用架构可以通过MHA工具进行实现。这个工具专门用来监听各个数据库的状态

   

## 分库分表

1. ### 怎么进行库表的拆分？

   一般库表拆分需要考虑三个维度，以订单表为例：

   1. 按订单id粒度去进行分库分表，

      - 即把订单id进行求hash后，
      - 对标数量进行取膜。
      - 然后把订单数据均匀分散到100-1000个表中去。
      - 再把表隽星的分散存储到多台服务器之中

   2. 存在的问题

      用户端：

      ​    用户一般需要根据userid查询自己的订单。故一般表会设计 my_index(userid,orderid)

      运营端

      ​    会根据条件查询所有的订单

   3. 会建立一张userid和orderid的映射关系表，然后针对userid为颗粒度去进行分表，即对userid进行取膜

   4. 分页查询时，根据映射关系进行分页查询

   5. 运营端： 一般将数据导入es中，然后在es中进行查询操作

2. 跨库分页一般怎么进行操作？

   1. 场景：

      如根据条件搜索订单信息，如排序规则、模糊搜索、条件状态搜索等

   2. 解决：

      在映射表中除了你的orderid字段外，还可以增加搜索条件，如my_index(userid,orderid,order_status)

   3. 方案：

      1. 如上所示，建立一张映射表，按主要业务id建立一个索引映射表
      2. 可以把查询条件都放到索引映射表中去
      3. 可以通过es进行数据查询

3. 分库分表后再怎么进行扩容？

   1. 不应该存在这种情况。可以在系统设计的时候将表多进行分散一些
   2. 容量满了： 将表多移动到几台服务器之中，然后修改路由规则